{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_data_dir = \"../data/colorData\"\n",
    "number_data_dir = \"../data/numberData\"\n",
    "special_card_data_dir = \"../data/specialCardData\"\n",
    "preprocessed_data_dir = \"../data/preprocessedData\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating, Loading and Saving preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for preprocessed data\n",
    "os.makedirs(preprocessed_data_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to load, preprocess, and save images\n",
    "def preprocess_and_save_images(directory, target_size=(300, 300)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    if os.path.isdir(directory):\n",
    "        for label in os.listdir(directory):\n",
    "            class_dir = os.path.join(directory, label)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    try:\n",
    "                        img = Image.open(img_path).convert('RGB')\n",
    "                        img = img.resize(target_size)\n",
    "                        img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "\n",
    "                        images.append(img_array)\n",
    "                        labels.append(label)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing image {img_path}: {e}\")\n",
    "    \n",
    "    # Encode labels as integers\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_dict = {label: index for index, label in enumerate(unique_labels)}\n",
    "    labels_encoded = np.array([label_dict[label] for label in labels], dtype=np.int64)\n",
    "\n",
    "    return np.array(images, dtype=np.float32), labels_encoded, unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Images and Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_images, color_labels, unique_color_labels = preprocess_and_save_images(color_data_dir)\n",
    "number_images, number_labels, unique_number_labels = preprocess_and_save_images(number_data_dir)\n",
    "special_card_images, special_card_labels, unique_special_labels = preprocess_and_save_images(special_card_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 2 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolor_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecial_card_images\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m all_color_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([color_labels, np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(number_labels), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(special_card_labels), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m      3\u001b[0m all_number_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(color_labels), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), number_labels, np\u001b[38;5;241m.\u001b[39mfull(\u001b[38;5;28mlen\u001b[39m(special_card_labels), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)])\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 2 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "all_images = np.concatenate([color_images, number_images, special_card_images], axis=0)\n",
    "all_color_labels = np.concatenate([color_labels, np.full(len(number_labels), -1), np.full(len(special_card_labels), -1)])\n",
    "all_number_labels = np.concatenate([np.full(len(color_labels), -1), number_labels, np.full(len(special_card_labels), -1)])\n",
    "all_special_labels = np.concatenate([np.full(len(color_labels), -1), np.full(len(number_labels), -1), special_card_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that all images and labels have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_images) == len(all_color_labels) == len(all_number_labels) == len(all_special_labels), \"Data lengths do not match!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_color, y_test_color, y_train_number, y_test_number, y_train_special, y_test_special =  train_test_split(\n",
    "                                                                                                                    all_images, \n",
    "                                                                                                                    all_color_labels,\n",
    "                                                                                                                    all_number_labels,\n",
    "                                                                                                                    all_special_labels,\n",
    "                                                                                                                    test_size=0.2,\n",
    "                                                                                                                    random_state=42\n",
    "                                                                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Tenorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset\n",
    "def create_dataset(images, color_labels, number_labels, special_labels, batch_size=16):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (images, {\"color_output\": color_labels, \"number_output\": number_labels, \"special_output\": special_labels})\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.shuffle(len(images)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation datasets\n",
    "train_dataset = create_dataset(X_train, y_train_color, y_train_number, y_train_special)\n",
    "test_dataset = create_dataset(X_test, y_test_color, y_test_number, y_test_special)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(300, 300, 3))\n",
    "x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_output = Dense(len(unique_color_labels), activation='softmax', name='color_output')(x)\n",
    "number_output = Dense(len(unique_number_labels), activation='softmax', name='number_output')(x)\n",
    "special_output = Dense(len(unique_special_labels), activation='softmax', name='special_output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input_layer, outputs=[color_output, number_output, special_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Model with Seperate Metrics for each Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss={'color_output': 'sparse_categorical_crossentropy',\n",
    "                    'number_output': 'sparse_categorical_crossentropy',\n",
    "                    'special_output': 'sparse_categorical_crossentropy'},\n",
    "              metrics={'color_output': 'accuracy',\n",
    "                       'number_output': 'accuracy',\n",
    "                       'special_output': 'accuracy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=20, \n",
    "                    validation_data=test_dataset\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to predict and display the result for a UNO card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_uno_card(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((300, 300))\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    # Make predictions\n",
    "    color_prediction, number_prediction, special_prediction = model.predict(img_array)\n",
    "    color_label = unique_color_labels[np.argmax(color_prediction)]\n",
    "    number_label = unique_number_labels[np.argmax(number_prediction)]\n",
    "    special_label = unique_special_labels[np.argmax(special_prediction)]\n",
    "\n",
    "    print(f\"Predicted color: {color_label}\")\n",
    "    print(f\"Predicted number: {number_label}\")\n",
    "    print(f\"Is special card: {special_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_uno_card(\"testing/red.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
